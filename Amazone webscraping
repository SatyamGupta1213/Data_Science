{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNS6KdT48SB/dc+VZ6n6hZJ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import requests\n","from bs4 import BeautifulSoup\n","import pandas as pd\n","import time\n","\n","def scrape_product_listings(url, num_pages):\n","    products = []\n","    for page in range(1, num_pages + 1):\n","        page_url = f\"{url}&page={page}\"\n","        response = requests.get(page_url)\n","        if response.status_code == 200:\n","            soup = BeautifulSoup(response.content, 'html.parser')\n","            listings = soup.find_all('div', {'data-component-type': 's-search-result'})\n","            for listing in listings:\n","                product_url = 'https://www.amazon.in' + listing.find('a', class_='a-link-normal')['href']\n","                product_name = listing.find('span', class_='a-size-medium').text\n","                product_price = listing.find('span', class_='a-offscreen').text\n","                product_rating = listing.find('span', {'class': 'a-icon-alt'})\n","                rating = product_rating.text.split()[0] if product_rating else None\n","                num_reviews = listing.find('span', {'class': 'a-size-base'}).text\n","                products.append({\n","                    'Product URL': product_url,\n","                    'Product Name': product_name,\n","                    'Product Price': product_price,\n","                    'Rating': rating,\n","                    'Number of Reviews': num_reviews\n","                })\n","        time.sleep(2)  # Adding a delay to avoid hitting the server too frequently\n","    return products\n","\n","def scrape_product_details(product_urls):\n","    product_data = []\n","    for url in product_urls:\n","        response = requests.get(url)\n","        if response.status_code == 200:\n","            soup = BeautifulSoup(response.content, 'html.parser')\n","            product_description = soup.find('div', {'id': 'productDescription'}).text.strip() if soup.find('div', {'id': 'productDescription'}) else None\n","            manufacturer = soup.find('a', {'id': 'bylineInfo'}).text.strip() if soup.find('a', {'id': 'bylineInfo'}) else None\n","            asin = soup.find('span', {'class': 'prodDetSectionEntry'}).text.strip().split(\":\")[1] if soup.find('span', {'class': 'prodDetSectionEntry'}) else None\n","            product_data.append({\n","                'Product URL': url,\n","                'Description': product_description,\n","                'ASIN': asin,\n","                'Product Description': product_description,\n","                'Manufacturer': manufacturer\n","            })\n","        time.sleep(2)  # Adding a delay to avoid hitting the server too frequently\n","    return product_data\n","\n","if __name__ == \"__main__\":\n","    base_url = \"https://www.amazon.in/s?k=bags&crid=2M096C61O4MLT&qid=1653308124&sprefix=ba%2Caps%2C283&ref=sr_pg_\"\n","    num_pages_to_scrape = 20\n","    num_product_urls_to_scrape = 200\n","\n","    # Step 1: Scrape product listings\n","    product_listings = scrape_product_listings(base_url, num_pages_to_scrape)\n","\n","    # Step 2: Extract product URLs from product listings\n","    product_urls = [product['Product URL'] for product in product_listings]\n","\n","    # Step 3: Scrape product details from the extracted URLs\n","    product_details = scrape_product_details(product_urls[:num_product_urls_to_scrape])\n","\n","    # Step 4: Combine the two data sets\n","    combined_data = []\n","    for listing, detail in zip(product_listings, product_details):\n","        combined_data.append({**listing, **detail})\n","\n","    # Step 5: Convert the combined data to a pandas DataFrame\n","    df = pd.DataFrame(combined_data)\n","\n","    # Step 6: Export the DataFrame to a CSV file\n","    df.to_csv('amazon_product_data.csv', index=False)\n","\n","    print(\"Data has been scraped and exported to 'amazon_product_data.csv'.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mpgoppCVFe-q","executionInfo":{"status":"ok","timestamp":1690004117701,"user_tz":-330,"elapsed":152982,"user":{"displayName":"satyam gupta","userId":"13613629701658596535"}},"outputId":"e116673b-9e80-4dbe-f489-e0b9e49ad9f0"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Data has been scraped and exported to 'amazon_product_data.csv'.\n"]}]}]}